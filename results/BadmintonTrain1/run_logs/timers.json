{
    "name": "root",
    "gauges": {
        "Badminton.Policy.Entropy.mean": {
            "value": 1.7924137115478516,
            "min": 1.7147215604782104,
            "max": 2.4653639793395996,
            "count": 817
        },
        "Badminton.Policy.Entropy.sum": {
            "value": 7065.69482421875,
            "min": 6414.8642578125,
            "max": 10732.513671875,
            "count": 817
        },
        "Badminton.Environment.EpisodeLength.mean": {
            "value": 24.050632911392405,
            "min": 19.926315789473684,
            "max": 30.123076923076923,
            "count": 817
        },
        "Badminton.Environment.EpisodeLength.sum": {
            "value": 3800.0,
            "min": 3716.0,
            "max": 3968.0,
            "count": 817
        },
        "Badminton.Self-play.ELO.mean": {
            "value": 1200.5762708651832,
            "min": 1065.379691908296,
            "max": 1347.6100969255026,
            "count": 817
        },
        "Badminton.Self-play.ELO.sum": {
            "value": 94845.52539834948,
            "min": 74576.57843358073,
            "max": 114771.25097546879,
            "count": 817
        },
        "Badminton.Step.mean": {
            "value": 1633981.0,
            "min": 1988.0,
            "max": 1633981.0,
            "count": 817
        },
        "Badminton.Step.sum": {
            "value": 1633981.0,
            "min": 1988.0,
            "max": 1633981.0,
            "count": 817
        },
        "Badminton.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.3419380486011505,
            "min": -0.3649708926677704,
            "max": 0.5713880062103271,
            "count": 817
        },
        "Badminton.Policy.ExtrinsicValueEstimate.sum": {
            "value": 27.013105392456055,
            "min": -29.20616340637207,
            "max": 50.282142639160156,
            "count": 817
        },
        "Badminton.Environment.CumulativeReward.mean": {
            "value": 0.569620253164557,
            "min": -0.6164383561643836,
            "max": 0.6486486486486487,
            "count": 817
        },
        "Badminton.Environment.CumulativeReward.sum": {
            "value": 45.0,
            "min": -47.0,
            "max": 50.0,
            "count": 817
        },
        "Badminton.Policy.ExtrinsicReward.mean": {
            "value": 0.569620253164557,
            "min": -0.6164383561643836,
            "max": 0.6486486486486487,
            "count": 817
        },
        "Badminton.Policy.ExtrinsicReward.sum": {
            "value": 45.0,
            "min": -47.0,
            "max": 50.0,
            "count": 817
        },
        "Badminton.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 817
        },
        "Badminton.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 817
        },
        "Badminton.Losses.PolicyLoss.mean": {
            "value": 0.0170437878172379,
            "min": 0.011612830142439634,
            "max": 0.021502018091268837,
            "count": 79
        },
        "Badminton.Losses.PolicyLoss.sum": {
            "value": 0.0170437878172379,
            "min": 0.011612830142439634,
            "max": 0.021502018091268837,
            "count": 79
        },
        "Badminton.Losses.ValueLoss.mean": {
            "value": 0.06260849889367819,
            "min": 0.06048962641507387,
            "max": 0.1423467008396983,
            "count": 79
        },
        "Badminton.Losses.ValueLoss.sum": {
            "value": 0.06260849889367819,
            "min": 0.06048962641507387,
            "max": 0.1423467008396983,
            "count": 79
        },
        "Badminton.Policy.LearningRate.mean": {
            "value": 0.0002,
            "min": 0.0002,
            "max": 0.0002,
            "count": 79
        },
        "Badminton.Policy.LearningRate.sum": {
            "value": 0.0002,
            "min": 0.0002,
            "max": 0.0002,
            "count": 79
        },
        "Badminton.Policy.Epsilon.mean": {
            "value": 0.15,
            "min": 0.15,
            "max": 0.15,
            "count": 79
        },
        "Badminton.Policy.Epsilon.sum": {
            "value": 0.15,
            "min": 0.15,
            "max": 0.15,
            "count": 79
        },
        "Badminton.Policy.Beta.mean": {
            "value": 0.003,
            "min": 0.003,
            "max": 0.003,
            "count": 79
        },
        "Badminton.Policy.Beta.sum": {
            "value": 0.003,
            "min": 0.003,
            "max": 0.003,
            "count": 79
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1716229163",
        "python_version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\aaron\\BlockBadminton\\block-badminton\\venv\\Scripts\\mlagents-learn config/trainer_config.yaml --run-id=BadmintonTrain1",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu115",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1716233932"
    },
    "total": 4768.5050346,
    "count": 1,
    "self": 0.006092200000239245,
    "children": {
        "run_training.setup": {
            "total": 0.11625870000000038,
            "count": 1,
            "self": 0.11625870000000038
        },
        "TrainerController.start_learning": {
            "total": 4768.3826837,
            "count": 1,
            "self": 5.713551599951643,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.215623000000434,
                    "count": 17,
                    "self": 11.215623000000434
                },
                "TrainerController.advance": {
                    "total": 4751.008844000048,
                    "count": 236171,
                    "self": 5.22987219994684,
                    "children": {
                        "env_step": {
                            "total": 4088.726049000033,
                            "count": 236171,
                            "self": 2369.734991800173,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1715.8831087999065,
                                    "count": 236171,
                                    "self": 26.706800799920984,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1689.1763079999855,
                                            "count": 363884,
                                            "self": 1689.1763079999855
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 3.1079483999536137,
                                    "count": 236170,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 4689.452905599963,
                                            "count": 236170,
                                            "is_parallel": true,
                                            "self": 2754.2973037999154,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.010627900000358181,
                                                    "count": 34,
                                                    "is_parallel": true,
                                                    "self": 0.005768599999708357,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.004859300000649824,
                                                            "count": 68,
                                                            "is_parallel": true,
                                                            "self": 0.004859300000649824
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1935.1449739000473,
                                                    "count": 236170,
                                                    "is_parallel": true,
                                                    "self": 42.78249129994197,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 58.23581769997484,
                                                            "count": 236170,
                                                            "is_parallel": true,
                                                            "self": 58.23581769997484
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1697.9902781000892,
                                                            "count": 236170,
                                                            "is_parallel": true,
                                                            "self": 1697.9902781000892
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 136.13638680004124,
                                                            "count": 472340,
                                                            "is_parallel": true,
                                                            "self": 74.51686560006705,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 61.61952119997419,
                                                                    "count": 944680,
                                                                    "is_parallel": true,
                                                                    "self": 61.61952119997419
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 657.0529228000681,
                            "count": 236170,
                            "self": 22.875441399998977,
                            "children": {
                                "process_trajectory": {
                                    "total": 278.4610689000701,
                                    "count": 236170,
                                    "self": 277.81352900007,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.6475399000000834,
                                            "count": 3,
                                            "self": 0.6475399000000834
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 355.716412499999,
                                    "count": 79,
                                    "self": 281.80675899998886,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 73.90965350001018,
                                            "count": 3160,
                                            "self": 73.90965350001018
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.4446650999998383,
                    "count": 1,
                    "self": 0.006789399999433954,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.4378757000004043,
                            "count": 1,
                            "self": 0.4378757000004043
                        }
                    }
                }
            }
        }
    }
}